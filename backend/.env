# Coordinator (Router): Llama 3.2 (3B)
# Why: Extremely fast, lightweight, and optimized for tool calling/JSON. 
# Much faster than Llama 3.1 8B.
MODEL_FAST=llama3.2

# Architect (Planner): DeepSeek R1 (8B)
# Why: State-of-the-art "Reasoning" model (distilled). 
# Excels at complex planning and Chain of Thought (CoT).
MODEL_REASONING=deepseek-r1:8b

# Engineer (Coder): Qwen 2.5 Coder (7B)
# Why: Currently the best open-source coding model in its size class.
# Outperforms Llama 3.1 and others in code generation benchmarks.
MODEL_CODING=qwen2.5-coder:7b

OLLAMA_HOST=http://127.0.0.1:11434
MAX_AGENT_STEPS=10
SUDO_USER=skynet
SUDO_PASSWORD=foobar
TELEGRAM_TOKEN=your_telegram_bot_token_here